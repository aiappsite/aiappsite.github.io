---
title: 初识 GPT
tags: [GPT, ChatGPT, LLM]
categories:
  - 大模型
feature: true
---

在了解 GPT 之前，我们先普及一些基本概念：

![](https://cdn.jsdelivr.net/gh/0326/imgs@main/blog/1-1.png)

AI（artificial intelligence，人工智能）有不同的定义，但其中一个定义或已成为共识，即 AI 是一类计算机系统，它能够执行通常需要人类智能才能完成的任务。

ML（machine learning，机器学习）是 AI 的一个子集。在 ML 中，我们不试图直接实现 AI 系统使用的决策规则。相反，我们试图开发算法，使系统能够通过示例自己学习。自从在 20 世纪 50 年代开始进行 ML 研究以来，人们已经在科学文献中提出了许多 ML 算法。

DL（deep learning，深度学习）算法就是上述 ML 算法中的一种，是一种专注于受大脑结构启发的算法。这些算法被称为人工神经网络（artificial neural network）。它们可以处理大量的数据，并且在图像识别、语音识别及 NLP 等任务上表现出色。

GPT-4 和 ChatGPT 基于一种特定的神经网络架构，即 Transformer。Transformer 就像阅读机一样，它关注句子或段落的不同部分，以理解其上下文并产生连贯的回答。此外，它还可以理解句子中的单词顺序和上下文意思。这使 Transformer 在语言翻译、问题回答和文本生成等任务中非常有效。

## 大模型

LLM（large language model, 大语言模型）简称大模型，它们能够以非常高的准确性识别和生成人类可读的文本。这又涉及到另外一个概念：NLP（natural language processing，自然语言处理），LLM、GPT-4、ChatGPT 都是 NLP 领域的一种模型，而 NLP 则是机器学习和人工智能的一个子领域，专注于使计算机能够处理、解释和生成人类语言。现代 NLP 解决方案基于 ML 算法。NLP 的目标是让计算机能够处理自然语言文本。这个目标涉及诸多任务，如下所述。

- 文本分类：将输入文本归为预定义的类别。这类任务包括情感分析和主题分类。比如，某公司使用情感分析将用户邮件分为"个人邮件"，"社交邮件"和"垃圾邮件"；
- 自动翻译：将文本从一种语言自动翻译成另一种语言（当然也包括编程语言）；
- 问题回答：根据给定的文本回答问题，比如智能客服；
- 文本生成：根据给定的输入文本（prompt 提示词）生成连贯且相关的输出文本；

LLM 是试图完成文本生成任务的一类 ML 模型。LLM 使计算机能够处理、解释和生成人类语言，从而提高人机交互效率。为了做到这一点，LLM 会分析大量文本数据或基于这些数据进行训练，从而学习句子中各词之间的模式和关系。这个学习过程可以使用各种数据源，包括维基百科、Reddit、成千上万本书，甚至互联网本身。在给定输入文本的情况下，这个学习过程使得 LLM 能够预测最有可能出现的后续单词，从而生成对输入文本有意义的回应。

LLM 的发展可以追溯到几年前。它始于简单的语言模型，如 n-gram 模型。n-gram 模型通过使用词频来根据前面的词预测句子中的下一个词，其预测结果是在训练文本中紧随前面的词出现的频率最高的词。虽然这种方法提供了不错的着手点，但是 n-gram 模型在理解上下文和语法方面仍需改进，因为它有时会生成不连贯的文本。为了提高 n-gram 模型的性能，人们引入了更先进的学习算法，包括循环神经网络（recurrent neural network，RNN）和长短期记忆（long short-termmemory，LSTM）网络。与 n-gram 模型相比，这些模型能够学习更长的序列，并且能够更好地分析上下文，但它们在处理大量数据时的效率仍然欠佳。尽管如此，在很长的一段时间里，这些模型算是最高效的，因此在自动翻译等任务中被广泛使用。

## Transformer 架构

Transformer 架构彻底改变了 NLP 领域，这主要是因为它能够有效地解决之前的 NLP 模型（如 RNN）存在的一个关键问题：很难处理长文本序列并记住其上下文。换句话说，RNN 在处理长文本序列时容易忘记上下文（也就是臭名昭著的"灾难性遗忘问题"），Transformer 则具备高效处理和编码上下文的能力。

这场革命的核心支柱是注意力机制，这是一个简单而又强大的机制。模型不再将文本序列中的所有词视为同等重要，而是在任务的每个步骤中关注最相关的词。**交叉注意力**和**自注意力**是基于注意力机制的两个架构模块，它们经常出现在 LLM 中。Transformer 架构广泛使用了交叉注意力模块和自注意力模块。

**交叉注意力**有助于模型确定输入文本的不同部分与输出文本中下一个词的相关性。它就像一盏聚光灯，照亮输入文本中的词或短语，并突出显示预测下一个词所需的相关信息，同时忽略不重要的细节。

**自注意力**机制是指模型能够关注其输入文本的不同部分。具体到 NLP 领域，自注意力机制使模型能够评估句子中的每个词相比于其他词的重要性。这使得模型能够更好地理解各词之间的关系，并根据输入文本中的多个词构建新念。

与 RNN 不同，Transformer 架构具有易于并行化的优势。这意味着Transformer 架构可以同时处理输入文本的多个部分，而无须顺序处理。这样做可以提高计算速度和训练速度，因为模型的不同部分可以并行工作，而无须等待前一步骤完成。基于 Transformer 架构的模型所具备的并行处理能力与图形处理单元（graphics processing unit，GPU）的架构完美契合，后者专用于同时处理多个计算任务。由于高度的并行性和强大的计算能力，GPU 非常适合用于训练和运行基于 Transformer 架构的模型。硬件上的这一进展使数据科学家能够在大型数据集上训练模型，从而为开发 LLM 铺平了道路。

Transformer 架构由来自谷歌公司的 Ashish Vaswani 等人在 2017 年的论文"Attention Is All You Need"中提出，最初用于序列到序列的任务，如机器翻译任务。标准的 Transformer 架构有两个主要组件：编码器和解码器，两者都十分依赖注意力机制。编码器的任务是处理输入文本，识别有价值的特征，并生成有意义的文本表示，称为嵌入（embedding）。解码器使用这个嵌入来生成一个输出，比如翻译结果或摘要文本。这个输出有效地解释了编码信息。

**生成式预训练** Transformer（Generative Pre-trained Transformer，GPT）是一类基于 Transformer 架构的模型，专门利用原始架构中的解码器部分。在 GPT 中，不存在编码器，因此无须通过交叉注意力机制来整合编码器产生的嵌入。也就是说，GPT 仅依赖解码器内部的自注意力机制来生成上下文感知的表示和预测结果。

![](https://cdn.jsdelivr.net/gh/0326/imgs@main/blog/1-2.png)

GPT 模型接收一段提示词作为输入，然后生成一段文本作为输出。这个过程被称为**文本补全**。举例来说，提示词可以是 The weather is nice today, so I decided to（今天天气很好，所以我决定），模型的输出则可能是 go for awalk（去散步）。

当 GPT 模型收到一段提示词之后，它首先将输入拆分成标记（token）。这些标记代表单词、单词的一部分、空格或标点符号。比如，在前面的例子中，提示词可以被拆分成［The, wea, ther, is, nice, today,,, so, I, de, ci, ded, to］。
因为有了注意力机制和 Transformer 架构，LLM 能够轻松处理标记并解释它们之间的关系及提示词的整体含义。Transformer 架构使模型能够高效地识别文本中的关键信息和上下文。

为了生成新的句子，LLM 根据提示词的上下文预测最有可能出现的下一个标记。GPT 与之前的循环模型不同，带有注意力机制的 Transformer 架构使得 LLM 能够将上下文作为一个整体来考虑。基于这个上下文，模型为每个潜在的后续标记分配一个概率分数，然后选择概率最高的标记作为序列中的下一个标记。在前面的例子中，"今天天气很好，所以我决定"之后，下一个最佳标记可能是"去"。

接下来重复此过程，但现在上下文变为"今天天气很好，所以我决定去"，之前预测的标记"去"被添加到原始提示词中。这个过程会一直重复，直到形成一个完整的句子："今天天气很好，所以我决定去散步。"，下图展示了这个过程。

![](https://cdn.jsdelivr.net/gh/0326/imgs@main/blog/1-3.png)


## GPT 模型发展史
本节将回顾 OpenAI 的 GPT 模型从 GPT-1 到 GPT-4 的演变历程。

![](https://cdn.jsdelivr.net/gh/0326/imgs@main/blog/20250426132047050.png)

### GPT-1 无监督预训练
2018 年年中，就在 Transformer 架构诞生一年后，OpenAI 发表了一篇题为“Improving Language Understanding by Generative Pre-Training”的论文，作者是 Alec Radford 等人。这篇论文介绍了 GPT，也被称为 GPT-1。

在 GPT-1 出现之前，构建高性能 NLP 神经网络的常用方法是利用监督学习。这种学习技术使用大量的手动标记数据。GPT-1 的作者提出了一种新的学习过程，其中引入了无监督的预训练步骤。这个预训练步骤不需要标记数据。相反，他们训练模型来预测下一个标记。由于采用了可以并行化的 Transformer 架构，预训练步骤是在大量数据上进行的。

人们发现，GPT-1 在各种基本的文本补全任务中是有效的。在无监督学习阶段，该模型学习 BookCorpus 数据集并预测文本中的下一个词。然而，GPT-1 是小模型，它无法在不经过微调的情况下执行复杂任务。因此，人们将微调作为第二个监督学习步骤，让模型在一小部分手动标记的数据上进行微
调，从而适应特定的目标任务。比如，在情感分析等分类任务中，可能需要在一小部分手动标记的文本示例上重新训练模型，以使其达到不错的准确度。这个过程使模型在初始的预训练阶段习得的参数得到修改，从而更好地适应具体的任务。

尽管规模相对较小，但 GPT-1 在仅用少量手动标记的数据进行微调后，能够出色地完成多个 NLP 任务。GPT-1 的架构包括一个解码器（与原始Transformer 架构中的解码器类似），具有 1.17 亿个参数。作为首个 GPT 模型，它为更强大的模型铺平了道路。后续的 GPT 模型使用更大的数据集和更多的参数，更好地利用了 Transformer 架构的潜力。

### GPT-2 更大的数据集
2019 年初，OpenAI 提出了 GPT-2。这是 GPT-1 的一个扩展版本，其参数量和训练数据集的规模大约是 GPT-1 的 10 倍。这个新版本的参数量为 15亿，训练文本为 40 GB。2019 年 11 月，OpenAI 发布了完整版的 GPT-2 模型。

GPT-2 表明，使用更大的数据集训练更大的语言模型可以提高语言模型的任务处理能力，并使其在许多任务中超越已有模型。它还表明，更大的语言模型能够更好地处理自然语言。

### GPT-3 更大的模型和数据集
2020 年 6 月，OpenAI 发布了 GPT-3。GPT-2 和 GPT-3 之间的主要区别在于模型的大小和用于训练的数据量。GPT-3 比 GPT-2 大得多，它有 1750 亿个参数，这使其能够捕捉更复杂的模式。此外，GPT-3 是在更广泛的数据集上进行训练的。这包括 Common Crawl（它就像互联网档案馆，其中包含来自数十亿个网页的文本）和维基百科。这个训练数据集包括来自网站、书籍和文章的内容，使得 GPT-3 能够更深入地理解语言和上下文。因此，GPT-3在各种语言相关任务中都展示出更强的性能。此外，它在文本生成方面还展示出更强的连贯性和创造力。它甚至能够编写代码片段，如 SQL 查询，
并执行其他智能任务。此外，GPT-3 取消了微调步骤，而这在之前的 GPT模型中是必需的。

然而，GPT-3存在一个问题，即最终用户提供的任务与模型在训练过程中所见到的任务不一致。我们已经知道，语言模型根据输入文本的上下文来预测下一个标记。这个训练过程不一定与最终用户希望模型执行的任务一致。此外，增大语言模型的规模并不能从根本上使其更好地遵循用户的意图或指令。像GPT-3 这样的模型是在互联网数据上进行训练的。尽管数据源经过一定的筛选，但用于训练模型的数据仍然可能包含虚假信息或有问题的文本，比如涉及种族歧视、性别歧视等。因此，模型有时可能说错话，甚至说出有害的话。

### GPT-3 到 InstructGPT
2021 年，OpenAI 发布了 GPT-3 模型的新版本，并取名为 InstructGPT。与原始的 GPT-3 基础模型不同，InstructGPT 模型通过强化学习和人类反馈进行优化。这意味着 InstructGPT 模型利用反馈来学习和不断改进。这使得模型能够从人类指令中学习，同时使其真实性更大、伤害性更小。


从 GPT-3 模型到 InstructGPT 模型的训练过程主要有两个阶段：监督微调（supervised fine-tuning，SFT）和通过人类反馈进行强化学习（reinforcement learning from human feedback，RLHF）。每个阶段都会针对前一阶段的结果进行微调。也就是说，SFT 阶段接收 GPT-3 模型并返回一个新模型。RLHF 阶段接收该模型并返回 InstructGPT 版本。如下图：

![](https://cdn.jsdelivr.net/gh/0326/imgs@main/blog/20250426130235917.png)

在 SFT 阶段中，原始的 GPT-3 模型通过监督学习进行微调（步骤 1）。OpenAI 拥有一系列由最终用户创建的提示词。首先，从可用的提示词数据集中随机抽样。然后，要求一个人（称为标注员）编写一个示例来演示理想的回答。重复这个过程数千次，以获得一个由提示词和相应的理想回答组成的监督训练数据集。最后，使用该数据集微调 GPT-3 模型，以针对用户的提问提供更一致的回答。此时得到的模型称为 SFT 模型。

RLHF 阶段分为两个子步骤：首先训练奖励模型（步骤 2），然后使用奖励模型进行强化学习（步骤 3）。奖励模型的目标是自动为回答给出分数。当回答与提示词中的内容匹配时，奖励分数应该很高；当回答与提示词中的内容不匹配时，奖励分数应该很低。为了训练奖励模型，OpenAI 首先随机选择一个问题，并使用 SFT模型生成几个可能的答案。我们稍后将看到，通过一个叫作温度（temperature）的参数，可以针对同一输入生成许多回答。然后，要求标注员根据与提示词的匹配程度和有害程度等标准给这些回答排序。在多次重复此过程后，使用数据集微调 SFT 模型以进行评分。这个奖励模型将用于
构建最终的 InstructGPT 模型。

训练 InstructGPT 模型的最后一步是强化学习，这是一个迭代的过程。它从一个初始的生成式模型开始，比如 SFT 模型。然后随机选择一个提示词，让模型给出预测结果，由奖励模型来评估结果。根据得到的奖励分数，相应地更新生成式模型。这个过程可以在无须人工干预的情况下重复无数次，从而自动、高效地提高模型的性能。与基础的 GPT-3 模型相比，InstructGPT 模型能够针对用户的提问生成更准确的内容。

### GPT-3.5 和 ChatGPT
2022 年 3 月，OpenAI 发布了 GPT-3 的新版本。新模型可以编辑文本或向文本中插入内容。它们所用的训练数据截至 2021 年 6 月，OpenAI 称它们比先前的版本更强大。2022 年 11 月底，OpenAI 正式称这些模型为 GPT-3.5模型。

OpenAI 还提出了 Codex 模型，这是一个在数十亿行代码上进行了微调的GPT-3 模型。正是它给 GitHub Copilot 这款自动化编程工具赋予了强大的能力，为使用 Visual Studio Code、JetBrains 甚至 Neovim 等许多文本编辑器的开发人员提供了帮助。然而，Codex 模型在 2023 年 3 月被 OpenAI 弃用。相反，OpenAI 建议用户从 Codex 切换到 GPT-3.5 Turbo 或 GPT-4。与此同时，GitHub 发布了基于 GPT-4 的 Copilot X 版本，其功能比之前的版本多得多。

> OpenAI 对 Codex 模型的弃用提醒我们，使用应用程序接口存在固有风险：随着更高效的模型的开发和发布，它们可能会发生变化，甚至被停用。

2022 年 11 月，OpenAI 推出了 ChatGPT，并将其作为一种实验性的对话式模型。该模型经过了微调，采用上图所示的类似技术，在交互式对话中表现出色。ChatGPT 源自 GPT-3.5 系列，该系列为其开发奠定了基础。

### GPT-4 多模态交互的开拓者
GPT-4 于 2023 年 3 月发布，它的出现标志着 GPT 系列从单一文本模态迈向了多模态交互的新阶段。该模型不仅能够处理大规模文本数据，还引入了图文双模态输入，极大地拓宽了应用场景。在复杂任务处理上，GPT-4 展现出了卓越的能力。例如在处理长篇文档分析时，它能够快速提炼关键信息，准确把握文档主旨，并基于此生成高质量的摘要。在图像理解方面，结合文本描述，它可以对给定图像进行深入解读，从识别物体到分析场景氛围，为用户提供丰富且准确的信息。这一多模态能力的提升，使得 GPT-4 在教育、设计、科研等多个领域都具有巨大的应用潜力，为用户提供了更加智能、全面的服务体验。

### GPT-4v：强化视觉感知的革新
2023 年 9 月推出的 GPT-4v 进一步强化了 GPT-4 的视觉能力。它能够更深入地理解和分析图像输入，实现了视觉与文本的深度融合。通过大量图像和文本数据的预训练以及基于人类反馈的强化学习（RLHF）微调，GPT-4v 在多个视觉任务中表现出色。在物体检测方面，它能够精准识别出图像中各类常见物体，无论是行驶在路上的汽车、公园里的动物，还是家中的日常用品，都逃不过它的 “眼睛”。其光学字符识别（OCR）功能更是强大，不仅能识别印刷体文字，对手写文字也能准确转化为机器可读文本。此外，GPT-4v 还具备一定的人脸识别能力，能够从面部特征推断出人物的部分属性。不过，受限于当前技术，在处理复杂科学图表、医学扫描图像，以及理解精确空间布局、处理物体重叠等场景时，GPT-4v 仍存在一些局限性。尽管如此，它在视觉领域的突破已经为众多行业带来了新的机遇，如智能安防、辅助驾驶、图像编辑等。

### GPT-4o 全方位多模态交互的飞跃
2024 年 5 月发布的 GPT-4o 堪称 GPT 系列的又一里程碑（o即omni，有所有，全部之意），它实现了真正意义上的全方位多模态交互。作为一个原生多模态模型，GPT-4o 支持文本、音频和图像的任意组合输入，并能生成相应的文本、音频和图像输出。这意味着用户可以向模型提供一段包含文字描述、图片和语音讲解的混合信息，模型会综合理解并给出全面且准确的回应。例如，在一个产品设计项目中，设计师可以向 GPT-4o 输入产品草图、设计说明语音以及相关文字注释，模型能够基于这些多模态信息提供设计改进建议，甚至生成优化后的产品效果图和语音讲解。这种实时推理能力让 GPT-4o 在虚拟协作、智能创作等领域展现出了巨大的优势，为用户带来了前所未有的交互体验。

## 使用插件和微调优化 GPT
当你使用ChatGPT时，有时候会发现他一本正经的胡说八道，这种回答通常被称为 AI 幻觉，即 AI 自信地给出一个回答，但是这个回答是错误的，或者涉及虚构的信息。对于依赖 GPT 的用户来说，AI幻觉可能带来危险。你需要仔细核对并批判性地审视模型的回答。

GPT 模型有一定的局限性，例如其计算能力有限，本质上GPT是基于模型训练进行预测，而不是精确的计算。因此，OpenAI 也提供了插件服务，这些插件使模型能够与开发人员定义的应用程序接口（application program interface，API）进行交互。这个过程可以极大地增强 GPT 模型的能力，因为它们可以通过各种操作访问外部世界。

除此之外，还可以通过模型微调技术，提高现有模型在特定任务上的准确性。微调过程涉及使用特定的一组新数据重新训练现有的GPT 模型。新模型专为特定任务而设计，这个额外的训练过程让模型能够调节其内部参数，以适应给定的任务。经过微调的模型应该在该任务上表现得更好。比如，采用金融文本数据进行微调的模型应该能够更好地回应针对该领域的查询并生成相关性更强的内容。

## 总结
从简单的 n-gram 模型发展到 RNN、LSTM，再到先进的 Transformer 架构，LLM 已经取得了长足的进步。LLM 是可以处理和生成人类语言的计算机程序，它利用 ML 技术来分析大量的文本数据。通过使用自注意力机制和交叉注意力机制，Transformer 极大地增强了模型的语言理解能力。

自 2023 年初以来，GPT-4 和 ChatGPT 在 NLP 方面展现出了非凡的能力。它们为促进各行各业的 AI 应用程序快速发展做出了贡献，一直代表着最先进的 LLM 生产力。直到2025年春节，杭州一家公司丢出了一枚重磅炸弹：Deepseek。